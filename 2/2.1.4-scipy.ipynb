{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение оптимизационных задач в SciPy\n",
    "\n",
    "Познакомимся чуть подробнее с решением оптимизационных задач в библиотеке SkiPy.\n",
    "\n",
    "Для начала импортируем модуль `optimize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И определим некоторую функцию ([rosenbrock function](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%A0%D0%BE%D0%B7%D0%B5%D0%BD%D0%B1%D1%80%D0%BE%D0%BA%D0%B0)) на которой всё будем тестировать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    # The rosenbrock function\n",
    "    return 0.5 * (1 - x[0])**2 + (x[1] - x[0]**2)**2\n",
    "\n",
    "print(f([1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала попробуем применить какой-нибудь примитивный метод, например перебор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99999324  1.00001283]\n"
     ]
    }
   ],
   "source": [
    "result = optimize.brute(f, ((-5, 5), (-5, 5)))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если ваша функция имеет разрывы, может быть она не гладкая, то подойдет дифференциальная эволюция. Это генетический алгоритм, о генетических алгоритмах мы еще поговорим подробнее в дальнейшем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 7.3955709864469857e-32\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 3393\n",
      "     nit: 112\n",
      " success: True\n",
      "       x: array([ 1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "result = optimize.differential_evolution(f, ((-5, 5), (-5, 5)))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно, мы нашли точку минимума - `x: array([ 1.,  1.])`, нам потребовалось некоторое приличное количество итераций - `nit: 112`.\n",
    "\n",
    "Если же у вашей функции есть градиент, то можно воспользоваться градиентными методами. Для этого сначала мы определим градиент функции Розенброка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def g(x):\n",
    "    return np.array((-2 * 0.5 * (1 - x[0]) - 4 * x[0] * (x[1] - x[0]**2), 2 * (x[1] - x[0]**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше резонно задаться вопросом — а верно ли мы его выписали? Может быть он на самом деле другой? На этот случай есть функция `check_grad`, она позволяет это проверить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38418579102e-07\n"
     ]
    }
   ],
   "source": [
    "print(optimize.check_grad(f, g, [2, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из популярных градиентных методов — `bfgs`. Он достаточно хорошо решает задачу оптимизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "[ 1.00000582  1.00001285]\n"
     ]
    }
   ],
   "source": [
    "print(optimize.fmin_bfgs(f, [2, 2], fprime=g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь как вы видите, нам хватило 8 итераций - `Iterations: 8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 1.78380307372662e-11\n",
      " hess_inv: array([[ 0.95489061,  1.90006631],\n",
      "       [ 1.90006631,  4.27872379]])\n",
      "      jac: array([  9.88094725e-07,   2.41748897e-06])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 36\n",
      "      nit: 8\n",
      "     njev: 9\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 1.00000573,  1.00001265])\n"
     ]
    }
   ],
   "source": [
    "print(optimize.minimize(f, [2, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 1.8414093407262628e-11\n",
      " hess_inv: array([[ 0.95489113,  1.90006768],\n",
      "       [ 1.90006768,  4.27872719]])\n",
      "      jac: array([  9.88085521e-07,   2.41739812e-06])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 9\n",
      "      nit: 8\n",
      "     njev: 9\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 1.00000582,  1.00001285])\n"
     ]
    }
   ],
   "source": [
    "print(optimize.minimize(f, [2, 2], method='BFGS', jac=g)) # jac=g - передаем градиент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " final_simplex: (array([[ 0.99998568,  0.99996682],\n",
      "       [ 1.00002149,  1.00004744],\n",
      "       [ 1.0000088 ,  1.00003552]]), array([  1.23119954e-10,   2.50768082e-10,   3.59639951e-10]))\n",
      "           fun: 1.2311995365407462e-10\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 91\n",
      "           nit: 46\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.99998568,  0.99996682])\n"
     ]
    }
   ],
   "source": [
    "print(optimize.minimize(f, [2, 2], method='Nelder-Mead'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
